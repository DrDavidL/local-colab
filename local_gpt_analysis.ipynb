{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local GPT Analysis for Medical Students\n",
    "\n",
    "## ðŸ¤– Analyzing Data with Natural Language Questions\n",
    "\n",
    "This notebook demonstrates how to use **local large language models** to analyze medical data using plain English questions. Unlike cloud-based AI services, everything runs on your computer, ensuring complete data privacy.\n",
    "\n",
    "### Why This Approach Matters for Medical Students:\n",
    "- ðŸ”’ **Complete Privacy**: Your data never leaves your computer\n",
    "- ðŸ’¬ **Natural Language**: Ask questions in plain English, no complex coding required\n",
    "- ðŸ¥ **Medical Context**: Perfect for exploring healthcare datasets securely\n",
    "- ðŸ“Š **Instant Analysis**: Get immediate insights and visualizations\n",
    "\n",
    "### Important Notes:\n",
    "- **Always consult your PI** about methods, devices, and approach before analyzing real data\n",
    "- This method complements other data science techniques covered in separate notebooks\n",
    "- The local model (qwen3) works on older devices but must be downloaded first via Ollama\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Prerequisites\n",
    "\n",
    "### Required Setup:\n",
    "\n",
    "1. **Install Ollama** from https://ollama.ai\n",
    "2. **Download the qwen3:8b model**:\n",
    "   ```bash\n",
    "   ollama pull qwen3:8b\n",
    "   ```\n",
    "3. **Install requirements** per the README.md file\n",
    "\n",
    "### â±ï¸ First-Time Usage Note:\n",
    "**The first time you use the model, it takes longer to load** - don't be discouraged! Subsequent queries will be much faster as the model stays loaded in memory.\n",
    "\n",
    "### Why qwen3:8b?\n",
    "- Runs efficiently on older hardware\n",
    "- Good balance of performance and resource usage\n",
    "- Excellent for data analysis tasks\n",
    "- Completely offline operation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Setting Up Your Local Analysis Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing pandasai>=3.0.0b2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing pandasai-litellm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, '-U', '--quiet'])\n",
    "\n",
    "# Install required packages for this notebook\n",
    "required_packages = [\"pandasai>=3.0.0b2\", 'pandasai-litellm']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        install_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Now we prepare to use the libraries\n",
    "\n",
    "from pandasai_litellm.litellm import LiteLLM\n",
    "import pandasai as pai\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"âœ… Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Dataset loaded: 390 rows, 15 columns\n",
      "Ready for natural language analysis!\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pai.read_csv(\"data/predictdm.csv\")\n",
    "\n",
    "print(f\"ðŸ“Š Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(\"Ready for natural language analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Local language model ready!\n",
      "ðŸ’¡ Tip: First query may be slow while model loads\n"
     ]
    }
   ],
   "source": [
    "# Initialize the local language model\n",
    "# Note: First run may take 30-60 seconds to load the model\n",
    "model = LiteLLM(model=\"ollama/qwen3:8b\")\n",
    "\n",
    "pai.config.set({\n",
    "    \"llm\": model,\n",
    "    \"save_charts\": False\n",
    "})\n",
    "\n",
    "print(\"ðŸ¤– Local language model ready!\")\n",
    "print(\"ðŸ’¡ Tip: First query may be slow while model loads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Natural Language Data Analysis\n",
    "\n",
    "Now you can ask questions about your data in plain English! The local AI will interpret your questions and generate appropriate analysis code.\n",
    "\n",
    "### Example Questions You Can Ask:\n",
    "- \"What is the average age of patients?\"\n",
    "- \"Show me the distribution of glucose levels\"\n",
    "- \"Compare BMI between diabetic and non-diabetic patients\"\n",
    "- \"Create a scatter plot of age vs glucose\"\n",
    "- \"What percentage of patients have diabetes?\"\n",
    "\n",
    "### Let's Start with Basic Questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.10964912280701\n"
     ]
    }
   ],
   "source": [
    "# Ask about mean glucose for men\n",
    "# This demonstrates how natural language gets converted to data analysis\n",
    "# The first question takes longer as the model loads\n",
    "response = df.chat('What is the mean glucose for women?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exports/charts/temp_chart_6f37cdde-9bc1-4b79-b1fc-311b0391acf7.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create visualizations with natural language\n",
    "chart_response = df.chat(\"Plot age distribution\")\n",
    "# print(chart_response) # Uncomment to open the chart object as a saved PNG file\n",
    "display(Image(filename=chart_response.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exports/charts/temp_chart_e733cdaf-c100-4361-989b-3020b595e759.png\n"
     ]
    }
   ],
   "source": [
    "# More complex analysis with regression\n",
    "plot_response = df.chat(\"Plot glucose vs age with a regression line\")\n",
    "# print(plot_response) # Uncomment to open the chart object as a saved PNG file\n",
    "display(Image(filename=plot_response.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Try Your Own Questions\n",
    "\n",
    "Use the cells below to ask your own questions about the diabetes dataset, once all the above are run. Remember, you can ask in natural language!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your question here - try asking about different variables or relationships\n",
    "# Example: df.chat(\"What is the correlation between BMI and diabetes?\")\n",
    "\n",
    "your_response = df.chat(\"Your question here\")\n",
    "print(your_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another question - try asking for a different type of visualization\n",
    "# Example: df.chat(\"Create a box plot of glucose levels by gender\")\n",
    "\n",
    "another_response = df.chat(\"Your visualization request here\")\n",
    "# print(another_response) # Uncomment to open the chart object as a saved PNG file\n",
    "display(Image(filename=another_response.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Advanced Natural Language Queries\n",
    "\n",
    "The local LLM can handle more sophisticated analysis requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex statistical analysis\n",
    "complex_analysis = df.chat(\"Calculate the diabetes prevalence by age groups: under 30, 30-50, 50-70, and over 70\")\n",
    "print(complex_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-variable analysis\n",
    "multi_var = df.chat(\"Show me a correlation heatmap of all numeric variables\")\n",
    "# print(multi_var) # Uncomment to open the chart object as a saved PNG file\n",
    "display(Image(filename=multi_var.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”’ Security and Privacy Benefits\n",
    "\n",
    "### Why Local LLMs Matter for Medical Data:\n",
    "\n",
    "âœ… **Complete Data Privacy**: No data transmission to external servers  \n",
    "âœ… **HIPAA Compliance**: Maintains patient confidentiality  \n",
    "âœ… **Institutional Control**: Meets hospital/university data policies  \n",
    "âœ… **Audit Trail**: All analysis happens on your controlled environment  \n",
    "âœ… **No Internet Required**: Works offline once model is downloaded  \n",
    "\n",
    "### Best Practices:\n",
    "- Always discuss your analysis approach with your Principal Investigator\n",
    "- Ensure your device meets your institution's security requirements\n",
    "- Keep your local environment updated and secure\n",
    "- Document your analysis methods for reproducibility\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Tips for Effective Natural Language Queries\n",
    "\n",
    "### Good Question Patterns:\n",
    "- **Be specific**: \"Show glucose distribution for diabetic patients\" vs \"Show glucose\"\n",
    "- **Request context**: \"Compare average BMI between groups\" vs \"Calculate BMI\"\n",
    "- **Ask for visualizations**: \"Plot X vs Y\" or \"Create a histogram of Z\"\n",
    "- **Specify groupings**: \"Analyze by gender\", \"Group by age ranges\"\n",
    "\n",
    "### What the Local LLM Can Do:\n",
    "- Generate statistical summaries\n",
    "- Create various plot types (scatter, histogram, box plot, etc.)\n",
    "- Perform correlation analysis\n",
    "- Group and aggregate data\n",
    "- Calculate percentages and ratios\n",
    "- Filter and subset data\n",
    "\n",
    "### Performance Notes:\n",
    "- **First query**: May take 30-60 seconds (model loading)\n",
    "- **Subsequent queries**: Much faster (2-10 seconds)\n",
    "- **Complex requests**: May take longer but provide detailed analysis\n",
    "- **Model stays loaded**: Until you restart the notebook\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Next Steps\n",
    "\n",
    "This notebook focused on **natural language data analysis** using local LLMs. To expand your data science skills:\n",
    "\n",
    "1. **Explore other notebooks** in this collection for traditional data science methods\n",
    "2. **Practice with different datasets** to see how the LLM adapts\n",
    "3. **Combine approaches**: Use this for exploration, then traditional methods for detailed analysis\n",
    "4. **Learn prompt engineering**: Better questions lead to better analysis\n",
    "\n",
    "### Remember:\n",
    "- This is one tool in your data science toolkit\n",
    "- Always validate important findings with traditional statistical methods\n",
    "- Consult with your PI about appropriate use in research contexts\n",
    "- The local approach ensures your data remains secure and private\n",
    "\n",
    "**Happy analyzing with natural language! ðŸ¤–ðŸ“ŠðŸ”’**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recover (tools)",
   "language": "python",
   "name": "recover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
